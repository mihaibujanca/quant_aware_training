# @package _global_
experiment:
  name: transformer
  type: transformer

# Model architecture
model:
  d_model: 128
  n_heads: 4
  n_layers: 4
  d_ff: 512
  max_seq_len: 256
  dropout: 0.1

# Dataset
data:
  name: shakespeare
  seq_len: 128

# Training overrides
epochs: 10
learned_epochs: 5
batch_size: 64
lr: 3e-4
