{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6747e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Quantization Error Geometry: A Visual Exploration\n",
    "# ============================================================\n",
    "#\n",
    "# This notebook traces how quantization error regions evolve through\n",
    "# neural network layers, building intuition from simple to complex cases.\n",
    "#\n",
    "# All experiments use 2D for visualization clarity.\n",
    "# Scales are fixed across plots for fair comparison.\n",
    "#\n",
    "# Experiments:\n",
    "# 1. Uniform diagonal weights (baseline)\n",
    "# 2. Non-uniform diagonal weights (per-channel variation)\n",
    "# 3. Full matrices (channel mixing, rotation/shear)\n",
    "# 4. Multiple input points (error manifold)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "# Global settings\n",
    "BITS = 8\n",
    "DELTA = 1.0 / (2 ** (BITS - 1))\n",
    "N_LAYERS = 4\n",
    "\n",
    "# Fixed scale for all error plots (set after computing max errors)\n",
    "GLOBAL_ERROR_SCALE = None  # Will be set after experiments\n",
    "\n",
    "# Colors\n",
    "COLORS = {\n",
    "    'layer1': '#1f77b4',\n",
    "    'layer2': '#ff7f0e', \n",
    "    'layer3': '#2ca02c',\n",
    "    'layer4': '#d62728',\n",
    "    'cumulative': '#e377c2',\n",
    "    'input': '#17becf',\n",
    "    'error_region': '#ff6b6b',\n",
    "    'reference': '#888888'\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Data structures for storing results\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class LayerStats:\n",
    "    \"\"\"Statistics for a single layer\"\"\"\n",
    "    layer_idx: int\n",
    "    weight_matrix: np.ndarray\n",
    "    spectral_norm: float\n",
    "    determinant: float\n",
    "    condition_number: float\n",
    "    error_half_widths: np.ndarray  # In input space\n",
    "    error_volume: float  # Area in 2D\n",
    "    \n",
    "@dataclass \n",
    "class ExperimentStats:\n",
    "    \"\"\"Statistics for a full experiment\"\"\"\n",
    "    name: str\n",
    "    input_point: np.ndarray\n",
    "    layer_stats: List[LayerStats]\n",
    "    cumulative_error_vertices: np.ndarray\n",
    "    cumulative_error_volume: float\n",
    "    bounding_box: np.ndarray  # [min, max] for each dim\n",
    "    relative_error: np.ndarray  # Per channel\n",
    "    \n",
    "    def summary(self):\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'input': self.input_point.tolist(),\n",
    "            'final_volume': self.cumulative_error_volume,\n",
    "            'bbox': self.bounding_box.tolist(),\n",
    "            'relative_error': self.relative_error.tolist(),\n",
    "            'spectral_norms': [ls.spectral_norm for ls in self.layer_stats],\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AllExperimentStats:\n",
    "    \"\"\"Container for all experiment results\"\"\"\n",
    "    experiments: Dict[str, ExperimentStats] = field(default_factory=dict)\n",
    "    \n",
    "    def add(self, stats: ExperimentStats):\n",
    "        self.experiments[stats.name] = stats\n",
    "    \n",
    "    def print_summary(self):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"SUMMARY OF ALL EXPERIMENTS\")\n",
    "        print(\"=\" * 70)\n",
    "        for name, stats in self.experiments.items():\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Input: {stats.input_point}\")\n",
    "            print(f\"  Final error volume: {stats.cumulative_error_volume:.6f}\")\n",
    "            print(f\"  Bounding box: {stats.bounding_box}\")\n",
    "            print(f\"  Relative error: {stats.relative_error}\")\n",
    "\n",
    "\n",
    "# Global stats container\n",
    "ALL_STATS = AllExperimentStats()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Core functions\n",
    "# ============================================================\n",
    "\n",
    "def quantize(W, delta=DELTA):\n",
    "    \"\"\"Quantize matrix to nearest grid point\"\"\"\n",
    "    return np.round(W / delta) * delta\n",
    "\n",
    "\n",
    "def get_box_vertices_2d(half_widths):\n",
    "    \"\"\"Get vertices of 2D box centered at origin\"\"\"\n",
    "    hw = np.array(half_widths)\n",
    "    return np.array([\n",
    "        [-hw[0], -hw[1]],\n",
    "        [-hw[0],  hw[1]],\n",
    "        [ hw[0],  hw[1]],\n",
    "        [ hw[0], -hw[1]]\n",
    "    ])\n",
    "\n",
    "\n",
    "def minkowski_sum_2d(V1, V2):\n",
    "    \"\"\"Minkowski sum of two 2D vertex sets\"\"\"\n",
    "    sums = []\n",
    "    for v1 in V1:\n",
    "        for v2 in V2:\n",
    "            sums.append(v1 + v2)\n",
    "    sums = np.array(sums)\n",
    "    \n",
    "    if len(sums) >= 3:\n",
    "        try:\n",
    "            hull = ConvexHull(sums)\n",
    "            return sums[hull.vertices]\n",
    "        except:\n",
    "            pass\n",
    "    return sums\n",
    "\n",
    "\n",
    "def compute_polygon_area(vertices):\n",
    "    \"\"\"Compute area of polygon using shoelace formula\"\"\"\n",
    "    if len(vertices) < 3:\n",
    "        return 0.0\n",
    "    try:\n",
    "        hull = ConvexHull(vertices)\n",
    "        return hull.volume  # In 2D, 'volume' is area\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def transform_vertices(vertices, W):\n",
    "    \"\"\"Apply linear transformation W to vertices\"\"\"\n",
    "    return vertices @ W.T\n",
    "\n",
    "\n",
    "def draw_polygon(ax, vertices, color, alpha=0.3, edgecolor=None, linewidth=2, label=None):\n",
    "    \"\"\"Draw a polygon from vertices\"\"\"\n",
    "    if len(vertices) < 3:\n",
    "        ax.scatter(vertices[:, 0], vertices[:, 1], c=color, s=50, label=label)\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        hull = ConvexHull(vertices)\n",
    "        hull_verts = vertices[hull.vertices]\n",
    "        hull_verts = np.vstack([hull_verts, hull_verts[0]])  # Close polygon\n",
    "        \n",
    "        ax.fill(hull_verts[:, 0], hull_verts[:, 1], color=color, alpha=alpha, label=label)\n",
    "        ax.plot(hull_verts[:, 0], hull_verts[:, 1], color=edgecolor or color, linewidth=linewidth)\n",
    "    except:\n",
    "        ax.scatter(vertices[:, 0], vertices[:, 1], c=color, s=50, label=label)\n",
    "\n",
    "\n",
    "def set_fixed_scale(ax, scale, center=(0, 0)):\n",
    "    \"\"\"Set fixed axis limits\"\"\"\n",
    "    ax.set_xlim(center[0] - scale, center[0] + scale)\n",
    "    ax.set_ylim(center[1] - scale, center[1] + scale)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axhline(0, color='k', linewidth=0.5)\n",
    "    ax.axvline(0, color='k', linewidth=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Experiment runner\n",
    "# ============================================================\n",
    "\n",
    "def run_experiment(name, x_input, weight_matrices, compute_error_fn):\n",
    "    \"\"\"\n",
    "    Run an experiment and collect statistics.\n",
    "    \n",
    "    Args:\n",
    "        name: Experiment name\n",
    "        x_input: Input point (2D)\n",
    "        weight_matrices: List of weight matrices (true, pre-quantization)\n",
    "        compute_error_fn: Function to compute error vertices at each layer\n",
    "    \n",
    "    Returns:\n",
    "        ExperimentStats object\n",
    "    \"\"\"\n",
    "    quant_weights = [quantize(W) for W in weight_matrices]\n",
    "    \n",
    "    layer_stats = []\n",
    "    val = x_input.copy()\n",
    "    cumulative_W = np.eye(2)\n",
    "    cumulative_error_vertices = None\n",
    "    \n",
    "    for i, (W_true, W) in enumerate(zip(weight_matrices, quant_weights)):\n",
    "        # Compute layer statistics\n",
    "        spectral_norm = np.linalg.norm(W, ord=2)\n",
    "        det = np.linalg.det(W)\n",
    "        svd = np.linalg.svd(W, compute_uv=False)\n",
    "        cond = svd.max() / svd.min() if svd.min() > 0 else np.inf\n",
    "        \n",
    "        # Compute error vertices for this layer\n",
    "        local_error_vertices = compute_error_fn(val, W, DELTA)\n",
    "        \n",
    "        # Map to input space\n",
    "        cumulative_W_after = W @ cumulative_W\n",
    "        try:\n",
    "            inv_W = np.linalg.inv(cumulative_W_after)\n",
    "            error_vertices_input = transform_vertices(local_error_vertices, inv_W)\n",
    "        except:\n",
    "            error_vertices_input = local_error_vertices\n",
    "        \n",
    "        # Minkowski sum\n",
    "        if cumulative_error_vertices is None:\n",
    "            cumulative_error_vertices = error_vertices_input\n",
    "        else:\n",
    "            cumulative_error_vertices = minkowski_sum_2d(cumulative_error_vertices, error_vertices_input)\n",
    "        \n",
    "        # Compute half-widths (bounding box of this layer's contribution)\n",
    "        hw = np.abs(error_vertices_input).max(axis=0)\n",
    "        \n",
    "        layer_stats.append(LayerStats(\n",
    "            layer_idx=i,\n",
    "            weight_matrix=W.copy(),\n",
    "            spectral_norm=spectral_norm,\n",
    "            determinant=det,\n",
    "            condition_number=cond,\n",
    "            error_half_widths=hw,\n",
    "            error_volume=compute_polygon_area(error_vertices_input)\n",
    "        ))\n",
    "        \n",
    "        # Update for next layer\n",
    "        val = W @ val\n",
    "        cumulative_W = cumulative_W_after\n",
    "    \n",
    "    # Final statistics\n",
    "    bbox_min = cumulative_error_vertices.min(axis=0)\n",
    "    bbox_max = cumulative_error_vertices.max(axis=0)\n",
    "    bbox = np.array([bbox_max - bbox_min])  # Full width\n",
    "    \n",
    "    rel_error = (bbox_max - bbox_min) / (2 * np.abs(x_input) + 1e-10)\n",
    "    \n",
    "    stats = ExperimentStats(\n",
    "        name=name,\n",
    "        input_point=x_input.copy(),\n",
    "        layer_stats=layer_stats,\n",
    "        cumulative_error_vertices=cumulative_error_vertices,\n",
    "        cumulative_error_volume=compute_polygon_area(cumulative_error_vertices),\n",
    "        bounding_box=np.array([bbox_min, bbox_max]),\n",
    "        relative_error=rel_error\n",
    "    )\n",
    "    \n",
    "    ALL_STATS.add(stats)\n",
    "    return stats, quant_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXPERIMENT 1: Uniform Diagonal Weights\n",
    "# ============================================================\n",
    "\n",
    "def exp1_error_fn(val, W, delta):\n",
    "    \"\"\"Error function for diagonal weights - produces axis-aligned box\"\"\"\n",
    "    # For diagonal W, error in each dim is independent\n",
    "    # error[i] = W_err[i,i] * val[i], W_err in [-delta/2, delta/2]\n",
    "    hw = (delta / 2) * np.abs(val)\n",
    "    return get_box_vertices_2d(hw)\n",
    "\n",
    "\n",
    "def run_experiment_1(x_input):\n",
    "    \"\"\"Experiment 1: Uniform diagonal weights\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXPERIMENT 1: Uniform Diagonal Weights\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # All layers have same weight on diagonal\n",
    "    weights = [\n",
    "        np.eye(2) * 0.9,\n",
    "        np.eye(2) * 1.1,\n",
    "        np.eye(2) * 0.85,\n",
    "        np.eye(2) * 1.05,\n",
    "    ]\n",
    "    \n",
    "    stats, quant_weights = run_experiment(\n",
    "        \"Exp1: Uniform Diagonal\",\n",
    "        x_input,\n",
    "        weights,\n",
    "        exp1_error_fn\n",
    "    )\n",
    "    \n",
    "    print(f\"Input: {x_input}\")\n",
    "    print(f\"Final error volume: {stats.cumulative_error_volume:.6f}\")\n",
    "    print(f\"Relative error: {stats.relative_error}\")\n",
    "    \n",
    "    return stats, quant_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXPERIMENT 2: Non-Uniform Diagonal Weights  \n",
    "# ============================================================\n",
    "\n",
    "def exp2_error_fn(val, W, delta):\n",
    "    \"\"\"Error function for diagonal weights - same as exp1\"\"\"\n",
    "    hw = (delta / 2) * np.abs(val)\n",
    "    return get_box_vertices_2d(hw)\n",
    "\n",
    "\n",
    "def run_experiment_2(x_input):\n",
    "    \"\"\"Experiment 2: Non-uniform diagonal weights\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXPERIMENT 2: Non-Uniform Diagonal Weights\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Different weights per channel\n",
    "    weights = [\n",
    "        np.diag([0.8, 1.2]),   # Ch1 amplified\n",
    "        np.diag([1.1, 0.7]),   # Ch0 amplified, Ch1 shrunk\n",
    "        np.diag([0.9, 1.1]),   # Mild\n",
    "        np.diag([1.2, 0.8]),   # Ch0 amplified\n",
    "    ]\n",
    "    \n",
    "    stats, quant_weights = run_experiment(\n",
    "        \"Exp2: Non-Uniform Diagonal\",\n",
    "        x_input,\n",
    "        weights,\n",
    "        exp2_error_fn\n",
    "    )\n",
    "    \n",
    "    print(f\"Input: {x_input}\")\n",
    "    print(f\"Final error volume: {stats.cumulative_error_volume:.6f}\")\n",
    "    print(f\"Relative error: {stats.relative_error}\")\n",
    "    \n",
    "    return stats, quant_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXPERIMENT 3: Full Matrices (Non-Diagonal)\n",
    "# ============================================================\n",
    "\n",
    "def exp3_error_fn(val, W, delta):\n",
    "    \"\"\"\n",
    "    Error function for full matrices.\n",
    "    \n",
    "    For full W, output error = W_err @ val where each W_err[i,j] is independent.\n",
    "    Output_err[i] = sum_j W_err[i,j] * val[j]\n",
    "    \n",
    "    This is a sum of independent terms, each in [-delta/2 * |val[j]|, delta/2 * |val[j]|].\n",
    "    The result is an axis-aligned box in output space.\n",
    "    \"\"\"\n",
    "    # Each output dim has error from all input dims\n",
    "    # hw[i] = delta/2 * sum_j |val[j]| = delta/2 * L1_norm(val)\n",
    "    l1_norm = np.sum(np.abs(val))\n",
    "    hw = (delta / 2) * l1_norm * np.ones(2)\n",
    "    return get_box_vertices_2d(hw)\n",
    "\n",
    "\n",
    "def run_experiment_3(x_input):\n",
    "    \"\"\"Experiment 3: Full matrices with off-diagonal elements\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXPERIMENT 3: Full Matrices (Non-Diagonal)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Matrices with rotation/shear\n",
    "    weights = [\n",
    "        np.array([[0.9, 0.2],\n",
    "                  [0.1, 1.0]]),\n",
    "        np.array([[0.95, -0.15],\n",
    "                  [0.2, 0.85]]),\n",
    "        np.array([[1.0, 0.1],\n",
    "                  [-0.1, 0.9]]),\n",
    "        np.array([[0.85, 0.15],\n",
    "                  [0.1, 1.05]]),\n",
    "    ]\n",
    "    \n",
    "    stats, quant_weights = run_experiment(\n",
    "        \"Exp3: Full Matrices\",\n",
    "        x_input,\n",
    "        weights,\n",
    "        exp3_error_fn\n",
    "    )\n",
    "    \n",
    "    print(f\"Input: {x_input}\")\n",
    "    print(f\"Final error volume: {stats.cumulative_error_volume:.6f}\")\n",
    "    print(f\"Relative error: {stats.relative_error}\")\n",
    "    \n",
    "    # Additional: compute cumulative transform properties\n",
    "    cumulative_W = np.eye(2)\n",
    "    for W in quant_weights:\n",
    "        cumulative_W = W @ cumulative_W\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(cumulative_W)\n",
    "    print(f\"Cumulative transform singular values: {S}\")\n",
    "    print(f\"Cumulative transform condition number: {S.max()/S.min():.3f}\")\n",
    "    \n",
    "    return stats, quant_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXPERIMENT 4: Multiple Input Points\n",
    "# ============================================================\n",
    "\n",
    "def run_experiment_4(base_weights):\n",
    "    \"\"\"Experiment 4: Error manifold - multiple input points\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXPERIMENT 4: Multiple Input Points (Error Manifold)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    quant_weights = [quantize(W) for W in base_weights]\n",
    "    \n",
    "    # Generate input manifold: circle\n",
    "    n_points = 32\n",
    "    theta = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "    radius = 20\n",
    "    circle_points = np.column_stack([radius * np.cos(theta), radius * np.sin(theta)])\n",
    "    \n",
    "    # Compute error for each point\n",
    "    results = []\n",
    "    for x in circle_points:\n",
    "        val = x.copy()\n",
    "        cumulative_W = np.eye(2)\n",
    "        cumulative_error_vertices = None\n",
    "        \n",
    "        for W in quant_weights:\n",
    "            local_error_vertices = exp3_error_fn(val, W, DELTA)\n",
    "            cumulative_W_after = W @ cumulative_W\n",
    "            \n",
    "            try:\n",
    "                inv_W = np.linalg.inv(cumulative_W_after)\n",
    "                error_vertices_input = transform_vertices(local_error_vertices, inv_W)\n",
    "            except:\n",
    "                error_vertices_input = local_error_vertices\n",
    "            \n",
    "            if cumulative_error_vertices is None:\n",
    "                cumulative_error_vertices = error_vertices_input\n",
    "            else:\n",
    "                cumulative_error_vertices = minkowski_sum_2d(cumulative_error_vertices, error_vertices_input)\n",
    "            \n",
    "            val = W @ val\n",
    "            cumulative_W = cumulative_W_after\n",
    "        \n",
    "        error_magnitude = np.max(np.linalg.norm(cumulative_error_vertices, axis=1))\n",
    "        results.append({\n",
    "            'input': x.copy(),\n",
    "            'error_vertices': cumulative_error_vertices.copy(),\n",
    "            'error_magnitude': error_magnitude,\n",
    "            'error_volume': compute_polygon_area(cumulative_error_vertices)\n",
    "        })\n",
    "    \n",
    "    # Statistics\n",
    "    magnitudes = [r['error_magnitude'] for r in results]\n",
    "    print(f\"Error magnitude range: [{min(magnitudes):.4f}, {max(magnitudes):.4f}]\")\n",
    "    print(f\"Variation ratio: {max(magnitudes)/min(magnitudes):.2f}x\")\n",
    "    \n",
    "    return results, circle_points, quant_weights\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plotting functions\n",
    "# ============================================================\n",
    "\n",
    "def plot_experiment_1_2(stats1, stats2, scale):\n",
    "    \"\"\"Plot comparison of Exp 1 and 2\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Row 1: Experiment 1\n",
    "    ax = axes[0, 0]\n",
    "    draw_polygon(ax, stats1.cumulative_error_vertices, COLORS['error_region'], alpha=0.4)\n",
    "    set_fixed_scale(ax, scale)\n",
    "    ax.set_title(f\"Exp 1: Uniform Diagonal\\nVolume: {stats1.cumulative_error_volume:.6f}\")\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    \n",
    "    # Per-layer contributions (Exp 1)\n",
    "    ax = axes[0, 1]\n",
    "    layers = [ls.layer_idx + 1 for ls in stats1.layer_stats]\n",
    "    hw0 = [ls.error_half_widths[0] for ls in stats1.layer_stats]\n",
    "    hw1 = [ls.error_half_widths[1] for ls in stats1.layer_stats]\n",
    "    x_pos = np.arange(len(layers))\n",
    "    ax.bar(x_pos - 0.2, hw0, 0.4, label='Dim 0', color=COLORS['layer1'])\n",
    "    ax.bar(x_pos + 0.2, hw1, 0.4, label='Dim 1', color=COLORS['layer2'])\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f'L{l}' for l in layers])\n",
    "    ax.set_ylabel('Error half-width')\n",
    "    ax.set_title('Exp 1: Per-layer error')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Relative error (Exp 1)\n",
    "    ax = axes[0, 2]\n",
    "    ax.bar(['Dim 0', 'Dim 1'], stats1.relative_error * 100, color=[COLORS['layer1'], COLORS['layer2']])\n",
    "    ax.set_ylabel('Relative error (%)')\n",
    "    ax.set_title('Exp 1: Relative error\\n(Should be equal for uniform weights)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 2: Experiment 2\n",
    "    ax = axes[1, 0]\n",
    "    draw_polygon(ax, stats2.cumulative_error_vertices, COLORS['error_region'], alpha=0.4)\n",
    "    set_fixed_scale(ax, scale)\n",
    "    ax.set_title(f\"Exp 2: Non-Uniform Diagonal\\nVolume: {stats2.cumulative_error_volume:.6f}\")\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    \n",
    "    # Per-layer contributions (Exp 2)\n",
    "    ax = axes[1, 1]\n",
    "    hw0 = [ls.error_half_widths[0] for ls in stats2.layer_stats]\n",
    "    hw1 = [ls.error_half_widths[1] for ls in stats2.layer_stats]\n",
    "    ax.bar(x_pos - 0.2, hw0, 0.4, label='Dim 0', color=COLORS['layer1'])\n",
    "    ax.bar(x_pos + 0.2, hw1, 0.4, label='Dim 1', color=COLORS['layer2'])\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f'L{l}' for l in layers])\n",
    "    ax.set_ylabel('Error half-width')\n",
    "    ax.set_title('Exp 2: Per-layer error')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Relative error (Exp 2)\n",
    "    ax = axes[1, 2]\n",
    "    ax.bar(['Dim 0', 'Dim 1'], stats2.relative_error * 100, color=[COLORS['layer1'], COLORS['layer2']])\n",
    "    ax.set_ylabel('Relative error (%)')\n",
    "    ax.set_title('Exp 2: Relative error\\n(Now DIFFERENT per channel)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/exp1_2_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_experiment_3(stats3, stats1, scale):\n",
    "    \"\"\"Plot Experiment 3 results\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Error region comparison\n",
    "    ax = axes[0]\n",
    "    draw_polygon(ax, stats1.cumulative_error_vertices, COLORS['layer1'], alpha=0.3, label='Exp1 (diagonal)')\n",
    "    draw_polygon(ax, stats3.cumulative_error_vertices, COLORS['error_region'], alpha=0.4, label='Exp3 (full)')\n",
    "    set_fixed_scale(ax, scale)\n",
    "    ax.set_title('Error region comparison\\nBlue=Diagonal, Red=Full matrices')\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Shape analysis via SVD\n",
    "    ax = axes[1]\n",
    "    centered = stats3.cumulative_error_vertices - stats3.cumulative_error_vertices.mean(axis=0)\n",
    "    U, S, Vt = np.linalg.svd(centered, full_matrices=False)\n",
    "    \n",
    "    ax.bar(['PC1', 'PC2'], S, color=[COLORS['layer1'], COLORS['layer2']])\n",
    "    ax.set_ylabel('Singular value')\n",
    "    ax.set_title(f'Error region shape (SVD)\\nCondition: {S[0]/S[1]:.2f}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Principal directions\n",
    "    ax = axes[2]\n",
    "    center = stats3.cumulative_error_vertices.mean(axis=0)\n",
    "    \n",
    "    draw_polygon(ax, stats3.cumulative_error_vertices, COLORS['error_region'], alpha=0.3)\n",
    "    \n",
    "    # Draw principal axes\n",
    "    for i, (s, v) in enumerate(zip(S, Vt)):\n",
    "        ax.arrow(center[0], center[1], v[0]*s*0.8, v[1]*s*0.8,\n",
    "                head_width=scale*0.03, color=['blue', 'green'][i], linewidth=2,\n",
    "                label=f'PC{i+1}: [{v[0]:.2f}, {v[1]:.2f}]')\n",
    "    \n",
    "    set_fixed_scale(ax, scale)\n",
    "    ax.set_title('Principal directions\\n(Error is anisotropic)')\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/exp3_full_matrices.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_experiment_4(results, circle_points, scale):\n",
    "    \"\"\"Plot Experiment 4 results\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 14))\n",
    "    \n",
    "    # Error magnitude around the circle\n",
    "    ax = axes[0, 0]\n",
    "    magnitudes = [r['error_magnitude'] for r in results]\n",
    "    scatter = ax.scatter(circle_points[:, 0], circle_points[:, 1],\n",
    "                        c=magnitudes, cmap='hot', s=100, edgecolors='black')\n",
    "    plt.colorbar(scatter, ax=ax, label='Error magnitude')\n",
    "    ax.plot(circle_points[:, 0], circle_points[:, 1], 'b-', alpha=0.3, linewidth=1)\n",
    "    ax.set_xlabel('Input dim 0')\n",
    "    ax.set_ylabel('Input dim 1')\n",
    "    ax.set_title('Circle manifold colored by error')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error magnitude vs angle\n",
    "    ax = axes[0, 1]\n",
    "    angles = np.arctan2(circle_points[:, 1], circle_points[:, 0])\n",
    "    ax.plot(np.degrees(angles), magnitudes, 'o-', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('Angle (degrees)')\n",
    "    ax.set_ylabel('Error magnitude')\n",
    "    ax.set_title('Error varies with direction\\n(Not constant around circle!)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Selected error regions\n",
    "    ax = axes[1, 0]\n",
    "    n_selected = 8\n",
    "    indices = np.linspace(0, len(results)-1, n_selected, dtype=int)\n",
    "    colors_selected = plt.cm.hsv(np.linspace(0, 1, n_selected))\n",
    "    \n",
    "    for idx, color in zip(indices, colors_selected):\n",
    "        r = results[idx]\n",
    "        draw_polygon(ax, r['error_vertices'], color, alpha=0.3, linewidth=1)\n",
    "    \n",
    "    set_fixed_scale(ax, scale)\n",
    "    ax.set_title('Error regions for 8 points around circle\\n(Shape varies with input direction)')\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    \n",
    "    # Manifold with error regions overlaid\n",
    "    ax = axes[1, 1]\n",
    "    error_scale = 0.5  # Scale factor to visualize error regions at each point\n",
    "    \n",
    "    for r in results[::2]:  # Every other point for clarity\n",
    "        vertices = r['error_vertices'] * error_scale + r['input']\n",
    "        draw_polygon(ax, vertices, COLORS['error_region'], alpha=0.2, linewidth=0.5)\n",
    "    \n",
    "    ax.plot(circle_points[:, 0], circle_points[:, 1], 'b-', linewidth=2, label='Input manifold')\n",
    "    ax.scatter(circle_points[:, 0], circle_points[:, 1], c='blue', s=20, zorder=5)\n",
    "    ax.set_xlabel('Input dim 0')\n",
    "    ax.set_ylabel('Input dim 1')\n",
    "    ax.set_title('Input manifold with error \"tubes\"\\n(Red = error region at each point)')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/exp4_error_manifold.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_summary(all_stats):\n",
    "    \"\"\"Summary comparison plot\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    exp_names = list(all_stats.experiments.keys())[:3]  # First 3 experiments\n",
    "    \n",
    "    # Volume comparison\n",
    "    ax = axes[0]\n",
    "    volumes = [all_stats.experiments[name].cumulative_error_volume for name in exp_names]\n",
    "    ax.bar(range(len(volumes)), volumes, color=[COLORS['layer1'], COLORS['layer2'], COLORS['layer3']])\n",
    "    ax.set_xticks(range(len(volumes)))\n",
    "    ax.set_xticklabels(['Uniform\\nDiagonal', 'Non-Uniform\\nDiagonal', 'Full\\nMatrices'], fontsize=9)\n",
    "    ax.set_ylabel('Error region volume (area)')\n",
    "    ax.set_title('Total error volume comparison')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overlay all error regions\n",
    "    ax = axes[1]\n",
    "    colors = [COLORS['layer1'], COLORS['layer2'], COLORS['layer3']]\n",
    "    alphas = [0.4, 0.3, 0.2]\n",
    "    \n",
    "    for name, color, alpha in zip(exp_names, colors, alphas):\n",
    "        stats = all_stats.experiments[name]\n",
    "        draw_polygon(ax, stats.cumulative_error_vertices, color, alpha=alpha, \n",
    "                    label=name.split(':')[1].strip())\n",
    "    \n",
    "    # Find max scale\n",
    "    max_extent = 0\n",
    "    for name in exp_names:\n",
    "        stats = all_stats.experiments[name]\n",
    "        max_extent = max(max_extent, np.abs(stats.cumulative_error_vertices).max())\n",
    "    \n",
    "    set_fixed_scale(ax, max_extent * 1.2)\n",
    "    ax.set_title('All error regions overlaid')\n",
    "    ax.set_xlabel('Dim 0')\n",
    "    ax.set_ylabel('Dim 1')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Spectral norms\n",
    "    ax = axes[2]\n",
    "    x_pos = np.arange(N_LAYERS)\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, (name, color) in enumerate(zip(exp_names, colors)):\n",
    "        stats = all_stats.experiments[name]\n",
    "        norms = [ls.spectral_norm for ls in stats.layer_stats]\n",
    "        ax.bar(x_pos + i*width, norms, width, label=name.split(':')[1].strip(), color=color, alpha=0.7)\n",
    "    \n",
    "    ax.set_xticks(x_pos + width)\n",
    "    ax.set_xticklabels([f'L{i+1}' for i in range(N_LAYERS)])\n",
    "    ax.set_ylabel('Spectral norm')\n",
    "    ax.set_title('Weight spectral norms by layer')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/all_experiments_summary.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main execution\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Common input point\n",
    "    x_input = np.array([10.0, 20.0])\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"QUANTIZATION ERROR GEOMETRY EXPERIMENTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Input point: {x_input}\")\n",
    "    print(f\"Quantization bits: {BITS}\")\n",
    "    print(f\"Delta: {DELTA}\")\n",
    "    \n",
    "    # Run experiments\n",
    "    stats1, weights1 = run_experiment_1(x_input)\n",
    "    stats2, weights2 = run_experiment_2(x_input)\n",
    "    stats3, weights3 = run_experiment_3(x_input)\n",
    "    \n",
    "    # Determine global scale for consistent plotting\n",
    "    all_vertices = [\n",
    "        stats1.cumulative_error_vertices,\n",
    "        stats2.cumulative_error_vertices,\n",
    "        stats3.cumulative_error_vertices\n",
    "    ]\n",
    "    GLOBAL_ERROR_SCALE = max(np.abs(v).max() for v in all_vertices) * 1.3\n",
    "    print(f\"\\nGlobal error scale for plots: {GLOBAL_ERROR_SCALE:.4f}\")\n",
    "    \n",
    "    # Experiment 4 uses weights from Exp 3\n",
    "    exp3_weights = [\n",
    "        np.array([[0.9, 0.2], [0.1, 1.0]]),\n",
    "        np.array([[0.95, -0.15], [0.2, 0.85]]),\n",
    "        np.array([[1.0, 0.1], [-0.1, 0.9]]),\n",
    "        np.array([[0.85, 0.15], [0.1, 1.05]]),\n",
    "    ]\n",
    "    results4, circle_points, weights4 = run_experiment_4(exp3_weights)\n",
    "    \n",
    "    # Plotting\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"GENERATING PLOTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    plot_experiment_1_2(stats1, stats2, GLOBAL_ERROR_SCALE)\n",
    "    plot_experiment_3(stats3, stats1, GLOBAL_ERROR_SCALE)\n",
    "    plot_experiment_4(results4, circle_points, GLOBAL_ERROR_SCALE)\n",
    "    plot_summary(ALL_STATS)\n",
    "    \n",
    "    # Print summary\n",
    "    ALL_STATS.print_summary()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"KEY TAKEAWAYS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "1. UNIFORM DIAGONAL: Error scales equally for all channels (relative error constant)\n",
    "   \n",
    "2. NON-UNIFORM DIAGONAL: Different channels accumulate error at different rates\n",
    "   - Channels with larger cumulative weights have smaller relative error\n",
    "   \n",
    "3. FULL MATRICES: Error region becomes tilted/sheared\n",
    "   - Can't analyze channels independently\n",
    "   - Bounding box overestimates true error region\n",
    "   - Principal components reveal error anisotropy\n",
    "   \n",
    "4. ERROR MANIFOLD: Error magnitude and shape vary with input position\n",
    "   - Further from origin = larger absolute error  \n",
    "   - Direction matters too (not just magnitude)\n",
    "   - The \"error tube\" around a manifold has varying thickness\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Manifold definitions\n",
    "# ============================================================\n",
    "\n",
    "def make_manifold(name, n_points=32, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate points on various 2D manifolds.\n",
    "    \n",
    "    Returns:\n",
    "        points: (n_points, 2) array\n",
    "        metadata: dict with manifold properties\n",
    "    \"\"\"\n",
    "    \n",
    "    if name == \"circle\":\n",
    "        radius = kwargs.get('radius', 20)\n",
    "        theta = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "        points = np.column_stack([radius * np.cos(theta), radius * np.sin(theta)])\n",
    "        metadata = {'radius': radius, 'type': 'closed'}\n",
    "        \n",
    "    elif name == \"ellipse\":\n",
    "        a = kwargs.get('a', 25)  # Semi-major axis\n",
    "        b = kwargs.get('b', 10)  # Semi-minor axis\n",
    "        theta = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "        points = np.column_stack([a * np.cos(theta), b * np.sin(theta)])\n",
    "        metadata = {'a': a, 'b': b, 'type': 'closed'}\n",
    "        \n",
    "    elif name == \"line\":\n",
    "        start = np.array(kwargs.get('start', [-25, -10]))\n",
    "        end = np.array(kwargs.get('end', [25, 10]))\n",
    "        t = np.linspace(0, 1, n_points)\n",
    "        points = start + t[:, np.newaxis] * (end - start)\n",
    "        metadata = {'start': start, 'end': end, 'type': 'open'}\n",
    "        \n",
    "    elif name == \"spiral\":\n",
    "        turns = kwargs.get('turns', 2)\n",
    "        r_min = kwargs.get('r_min', 5)\n",
    "        r_max = kwargs.get('r_max', 25)\n",
    "        theta = np.linspace(0, turns * 2 * np.pi, n_points)\n",
    "        r = np.linspace(r_min, r_max, n_points)\n",
    "        points = np.column_stack([r * np.cos(theta), r * np.sin(theta)])\n",
    "        metadata = {'turns': turns, 'r_min': r_min, 'r_max': r_max, 'type': 'open'}\n",
    "        \n",
    "    elif name == \"figure_eight\":\n",
    "        scale = kwargs.get('scale', 15)\n",
    "        t = np.linspace(0, 2*np.pi, n_points, endpoint=False)\n",
    "        points = np.column_stack([scale * np.sin(t), scale * np.sin(t) * np.cos(t)])\n",
    "        metadata = {'scale': scale, 'type': 'closed'}\n",
    "        \n",
    "    elif name == \"grid\":\n",
    "        extent = kwargs.get('extent', 25)\n",
    "        n_side = int(np.sqrt(n_points))\n",
    "        x = np.linspace(-extent, extent, n_side)\n",
    "        y = np.linspace(-extent, extent, n_side)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "        metadata = {'extent': extent, 'n_side': n_side, 'type': 'area'}\n",
    "        \n",
    "    elif name == \"two_blobs\":\n",
    "        n_each = n_points // 2\n",
    "        center1 = np.array(kwargs.get('center1', [-15, 0]))\n",
    "        center2 = np.array(kwargs.get('center2', [15, 0]))\n",
    "        std = kwargs.get('std', 5)\n",
    "        blob1 = np.random.randn(n_each, 2) * std + center1\n",
    "        blob2 = np.random.randn(n_points - n_each, 2) * std + center2\n",
    "        points = np.vstack([blob1, blob2])\n",
    "        metadata = {'center1': center1, 'center2': center2, 'std': std, 'type': 'clusters'}\n",
    "        \n",
    "    elif name == \"crescent\":\n",
    "        outer_r = kwargs.get('outer_r', 25)\n",
    "        inner_r = kwargs.get('inner_r', 15)\n",
    "        theta = np.linspace(0, np.pi, n_points)\n",
    "        outer = np.column_stack([outer_r * np.cos(theta), outer_r * np.sin(theta)])\n",
    "        # Offset inner arc\n",
    "        inner = np.column_stack([inner_r * np.cos(theta) + 5, inner_r * np.sin(theta) - 3])\n",
    "        points = outer  # Just use outer arc for simplicity\n",
    "        metadata = {'outer_r': outer_r, 'type': 'open'}\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown manifold: {name}\")\n",
    "    \n",
    "    return points, metadata\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run experiment 4 across all manifolds\n",
    "# ============================================================\n",
    "\n",
    "def compute_manifold_errors(points, quant_weights, delta=DELTA):\n",
    "    \"\"\"Compute error statistics for all points on a manifold.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for x in points:\n",
    "        val = x.copy()\n",
    "        cumulative_W = np.eye(2)\n",
    "        cumulative_error_vertices = None\n",
    "        \n",
    "        for W in quant_weights:\n",
    "            # Local error box\n",
    "            l1_norm = np.sum(np.abs(val))\n",
    "            hw = (delta / 2) * l1_norm\n",
    "            local_vertices = get_box_vertices_2d([hw, hw])\n",
    "            \n",
    "            # Map to input space\n",
    "            cumulative_W_after = W @ cumulative_W\n",
    "            try:\n",
    "                inv_W = np.linalg.inv(cumulative_W_after)\n",
    "                error_vertices_input = transform_vertices(local_vertices, inv_W)\n",
    "            except:\n",
    "                error_vertices_input = local_vertices\n",
    "            \n",
    "            # Minkowski sum\n",
    "            if cumulative_error_vertices is None:\n",
    "                cumulative_error_vertices = error_vertices_input\n",
    "            else:\n",
    "                cumulative_error_vertices = minkowski_sum_2d(\n",
    "                    cumulative_error_vertices, error_vertices_input\n",
    "                )\n",
    "            \n",
    "            val = W @ val\n",
    "            cumulative_W = cumulative_W_after\n",
    "        \n",
    "        error_magnitude = np.max(np.linalg.norm(cumulative_error_vertices, axis=1))\n",
    "        error_volume = compute_polygon_area(cumulative_error_vertices)\n",
    "        \n",
    "        results.append({\n",
    "            'input': x.copy(),\n",
    "            'error_vertices': cumulative_error_vertices.copy(),\n",
    "            'error_magnitude': error_magnitude,\n",
    "            'error_volume': error_volume,\n",
    "            'l1_norm': np.sum(np.abs(x)),\n",
    "            'l2_norm': np.linalg.norm(x)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_all_manifolds(quant_weights, manifold_names=None, n_points=32):\n",
    "    \"\"\"Run error analysis across multiple manifolds.\"\"\"\n",
    "    \n",
    "    if manifold_names is None:\n",
    "        manifold_names = ['circle', 'ellipse', 'line', 'spiral', 'figure_eight', 'two_blobs']\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for name in manifold_names:\n",
    "        print(f\"Processing manifold: {name}\")\n",
    "        points, metadata = make_manifold(name, n_points=n_points)\n",
    "        results = compute_manifold_errors(points, quant_weights)\n",
    "        \n",
    "        # Aggregate statistics\n",
    "        magnitudes = [r['error_magnitude'] for r in results]\n",
    "        volumes = [r['error_volume'] for r in results]\n",
    "        l1_norms = [r['l1_norm'] for r in results]\n",
    "        \n",
    "        all_results[name] = {\n",
    "            'points': points,\n",
    "            'metadata': metadata,\n",
    "            'results': results,\n",
    "            'stats': {\n",
    "                'error_mag_min': np.min(magnitudes),\n",
    "                'error_mag_max': np.max(magnitudes),\n",
    "                'error_mag_mean': np.mean(magnitudes),\n",
    "                'error_mag_std': np.std(magnitudes),\n",
    "                'error_vol_mean': np.mean(volumes),\n",
    "                'variation_ratio': np.max(magnitudes) / np.min(magnitudes),\n",
    "                'correlation_l1': np.corrcoef(l1_norms, magnitudes)[0, 1]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Visualization for multiple manifolds\n",
    "# ============================================================\n",
    "\n",
    "def plot_manifold_comparison(all_results, scale=None):\n",
    "    \"\"\"Compare error patterns across manifolds.\"\"\"\n",
    "    \n",
    "    n_manifolds = len(all_results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_manifolds + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Determine global scale if not provided\n",
    "    if scale is None:\n",
    "        max_input = 0\n",
    "        for name, data in all_results.items():\n",
    "            max_input = max(max_input, np.abs(data['points']).max())\n",
    "        scale = max_input * 1.4\n",
    "    \n",
    "    # Figure 1: Manifolds colored by error\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (name, data) in enumerate(all_results.items()):\n",
    "        ax = axes[idx]\n",
    "        points = data['points']\n",
    "        magnitudes = [r['error_magnitude'] for r in data['results']]\n",
    "        \n",
    "        scatter = ax.scatter(points[:, 0], points[:, 1], \n",
    "                            c=magnitudes, cmap='hot', s=60, edgecolors='black', linewidth=0.5)\n",
    "        plt.colorbar(scatter, ax=ax, label='Error mag')\n",
    "        \n",
    "        # Connect points if closed manifold\n",
    "        if data['metadata']['type'] == 'closed':\n",
    "            closed_points = np.vstack([points, points[0]])\n",
    "            ax.plot(closed_points[:, 0], closed_points[:, 1], 'b-', alpha=0.3, linewidth=1)\n",
    "        elif data['metadata']['type'] == 'open':\n",
    "            ax.plot(points[:, 0], points[:, 1], 'b-', alpha=0.3, linewidth=1)\n",
    "        \n",
    "        stats = data['stats']\n",
    "        ax.set_title(f\"{name}\\nVar ratio: {stats['variation_ratio']:.2f}x, \"\n",
    "                    f\"Corr(L1): {stats['correlation_l1']:.2f}\")\n",
    "        set_fixed_scale(ax, scale)\n",
    "        ax.set_xlabel('Dim 0')\n",
    "        ax.set_ylabel('Dim 1')\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(len(all_results), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/manifolds_error_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Figure 2: Summary statistics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    names = list(all_results.keys())\n",
    "    \n",
    "    # Error magnitude range\n",
    "    ax = axes[0]\n",
    "    mins = [all_results[n]['stats']['error_mag_min'] for n in names]\n",
    "    maxs = [all_results[n]['stats']['error_mag_max'] for n in names]\n",
    "    means = [all_results[n]['stats']['error_mag_mean'] for n in names]\n",
    "    \n",
    "    x_pos = np.arange(len(names))\n",
    "    ax.bar(x_pos, maxs, alpha=0.3, color='red', label='Max')\n",
    "    ax.bar(x_pos, means, alpha=0.5, color='blue', label='Mean')\n",
    "    ax.bar(x_pos, mins, alpha=0.7, color='green', label='Min')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Error magnitude')\n",
    "    ax.set_title('Error range by manifold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Variation ratio\n",
    "    ax = axes[1]\n",
    "    ratios = [all_results[n]['stats']['variation_ratio'] for n in names]\n",
    "    ax.bar(x_pos, ratios, color='purple', alpha=0.7)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Max/Min error ratio')\n",
    "    ax.set_title('Error variation within manifold\\n(Higher = more position-dependent)')\n",
    "    ax.axhline(1.0, color='gray', linestyle='--')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Correlation with L1 norm\n",
    "    ax = axes[2]\n",
    "    corrs = [all_results[n]['stats']['correlation_l1'] for n in names]\n",
    "    colors = ['green' if c > 0.8 else 'orange' if c > 0.5 else 'red' for c in corrs]\n",
    "    ax.bar(x_pos, corrs, color=colors, alpha=0.7)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.set_title('Correlation: Error vs L1 norm\\n(Green=predictable, Red=complex)')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.axhline(1.0, color='gray', linestyle='--')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/manifolds_statistics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def plot_manifold_error_regions(all_results, manifold_name, n_show=8, scale=None):\n",
    "    \"\"\"Show error regions for selected points on a specific manifold.\"\"\"\n",
    "    \n",
    "    data = all_results[manifold_name]\n",
    "    points = data['points']\n",
    "    results = data['results']\n",
    "    \n",
    "    if scale is None:\n",
    "        scale = np.max([r['error_magnitude'] for r in results]) * 1.5\n",
    "    \n",
    "    # Select evenly spaced points\n",
    "    indices = np.linspace(0, len(points)-1, n_show, dtype=int)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_show//2, figsize=(4*n_show//2, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, idx in zip(axes, indices):\n",
    "        r = results[idx]\n",
    "        vertices = r['error_vertices']\n",
    "        \n",
    "        draw_polygon(ax, vertices, COLORS['error_region'], alpha=0.4)\n",
    "        ax.scatter([0], [0], c='black', s=50, zorder=5)\n",
    "        \n",
    "        ax.set_title(f\"Input: ({r['input'][0]:.1f}, {r['input'][1]:.1f})\\n\"\n",
    "                    f\"Error: {r['error_magnitude']:.4f}\")\n",
    "        set_fixed_scale(ax, scale)\n",
    "    \n",
    "    plt.suptitle(f\"Error regions on {manifold_name} manifold\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/manifold_{manifold_name}_regions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main execution with manifolds\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use weights from experiment 3\n",
    "    base_weights = [\n",
    "        np.array([[0.9, 0.2], [0.1, 1.0]]),\n",
    "        np.array([[0.95, -0.15], [0.2, 0.85]]),\n",
    "        np.array([[1.0, 0.1], [-0.1, 0.9]]),\n",
    "        np.array([[0.85, 0.15], [0.1, 1.05]]),\n",
    "    ]\n",
    "    quant_weights = [quantize(W) for W in base_weights]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"MANIFOLD COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Run all manifolds\n",
    "    all_results = run_all_manifolds(\n",
    "        quant_weights,\n",
    "        manifold_names=['circle', 'ellipse', 'line', 'spiral', 'figure_eight', 'two_blobs'],\n",
    "        n_points=48\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"MANIFOLD STATISTICS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Manifold':<15} {'Min Error':<12} {'Max Error':<12} {'Var Ratio':<12} {'Corr(L1)':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    for name, data in all_results.items():\n",
    "        s = data['stats']\n",
    "        print(f\"{name:<15} {s['error_mag_min']:<12.4f} {s['error_mag_max']:<12.4f} \"\n",
    "              f\"{s['variation_ratio']:<12.2f} {s['correlation_l1']:<10.2f}\")\n",
    "    \n",
    "    # Plot\n",
    "    plot_manifold_comparison(all_results)\n",
    "    \n",
    "    # Show detailed error regions for spiral (interesting case)\n",
    "    plot_manifold_error_regions(all_results, 'spiral', n_show=8)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"OBSERVATIONS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "    1. CIRCLE: Constant radius but varying error  direction matters\n",
    "    \n",
    "    2. ELLIPSE: Similar to circle but stretched  error varies more\n",
    "    \n",
    "    3. LINE: Error grows with distance from origin  clear L1 relationship\n",
    "    \n",
    "    4. SPIRAL: Combines radial and angular effects  complex pattern\n",
    "    \n",
    "    5. FIGURE EIGHT: Self-intersecting  error high at extremes\n",
    "    \n",
    "    6. TWO BLOBS: Shows how clusters at different positions have different error\n",
    "    \n",
    "    KEY INSIGHT: Error depends on BOTH magnitude and direction of input.\n",
    "    The correlation with L1 norm tells you how \"predictable\" the error is.\n",
    "    Low correlation means direction effects dominate.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea92a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-aware-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
