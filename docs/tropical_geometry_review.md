# Review: docs/tropical_geometry.md (Tropical Geometry for Quantization)

This is a review of the *correctness* and *completeness* of the claims in `docs/tropical_geometry.md`. I did not modify the original document.

## High-level take

**What’s strong:**
- The document correctly emphasizes that ReLU networks are **piecewise-affine**, that **activation-pattern changes** are the discontinuities, and that within a fixed activation region the mapping (and therefore the error between two networks with the same region selection) is **exactly affine**.
- The mapping from project concepts (survive/dead/flip, region stability, affine-within-cell) to spline/tropical language is largely directionally correct.
- The “what’s useful vs rabbit holes” section is a good filter and generally aligned with the project goals.

**What needs tightening:**
- Some statements are **overstated as identities** when they are better phrased as “equivalent under conditions” (notably the “you are doing tropical geometry” theme and the role of integer weights).
- A few technical claims look **incorrect or too imprecise** (zonotope vertex-count formula; Lipschitz formula in the MASO section).
- The link from *neural network quantization* (rounding/clipping) to *tropical coefficient perturbation* is currently presented too directly; it needs a clearer bridge so it doesn’t read as category error.

---

## What looks correct (and worth keeping)

### Tropical basics
- The (max,+) semiring table is correct (tropical “addition” = max, “multiplication” = +). The identities (-∞ for max, 0 for +) are correct.
- Tropical polynomials as `max` of affine functions and therefore convex piecewise-linear functions: correct.
- Tropical hypersurface defined as points where the max is attained by ≥2 terms (kink locus): correct.
- Tropical rational function as subtraction of two tropical polynomials; and resulting piecewise-linear, not necessarily convex: directionally correct. (Any PL function can be written as difference of two convex PL functions, so the DC framing is reasonable.)

### “ReLU networks are piecewise-affine” / spline framing
- The ASO viewpoint `f(x) = A[x] x + b[x]` for piecewise-affine networks is correct as a representation *within regions* (and almost everywhere globally).
- “A[x] is the Jacobian within a region” is correct: for piecewise-affine maps, Jacobian is constant on each cell (almost everywhere) and equals the local linear map.
- The distinction “within-region error is affine; discontinuities happen at region boundaries” is correct and matches your “collapse makes things uncorrectable” narrative.

### Project mapping table
- Mapping `relu_flip_rate` ↔ activation-pattern disagreement / cell change is correct.
- “Error is linear within a region” aligns with your `linear_error_norm` measurement intent.
- “Local complexity not yet computed” is a good forward pointer.

---

## Likely incorrect / needs correction

### 1) Zonotope vertex-count bound
In **Insight 3: Zonotopes explain the Minkowski sum structure**, the document states:

> “a zonotope with n generators in R^d has at most 2·C(n-1, d-1) vertices.”

That formula is not the standard upper bound. The known maximal vertex count for a d-dimensional zonotope generated by n segments is:

- `2 * sum_{k=0}^{d-1} C(n-1, k)`

For d=2 this gives `2n`, matching the familiar polygon bound (up to off-by-constants depending on conventions). The document’s `2·C(n-1,d-1)` is generally too small for d>2.

Impact: this is one of the few places where a concrete combinatorial theorem is quoted; it should be fixed or removed.

### 2) MASO Lipschitz formula
In **Why the spline view matters for quantization → Lipschitz constants**, the document gives:

> `κ^(ℓ) = Σ_k max_r ||A^(ℓ)_{k,r}||²`

This looks dimensionally suspicious. For a scalar max-affine `max_r (a_r^T x + b_r)`, a standard Lipschitz bound is `max_r ||a_r||` (for the appropriate norm). For a vector-output stacking, the bound typically combines per-output bounds (e.g. via sqrt of sum of squares) depending on chosen norms.

Impact: the idea “Lipschitz bounds sensitivity” is correct and useful, but this exact formula should be double-checked and rewritten as a bound with explicit norm choices.

### 3) “Cumulative error region is exactly a zonotope” (scope needs qualification)
The statement is correct for the **weight-only / additive box error** constructions where each layer injects an axis-aligned box and you propagate/accumulate via linear maps and Minkowski sum.

However, once you incorporate **ReLU intersection/clipping** (or other nonlinear constraints), the resulting reachable error set is generally **not a zonotope** (it becomes a polytope intersection / union of polytopes). The document already discusses ReLU “chopping”, but the “exactly a zonotope” language should be scoped to the linear-additive regime.

---

## Overstatements / claims that need conditions or citations

### 1) “You’re already doing tropical geometry” / “mathematical identity”
The document claims the connection is “not a metaphor… it is a mathematical identity.”

What’s true:
- ReLU networks are piecewise-linear; tropical/spline frameworks give formal languages for piecewise-linear functions.

What needs toning down:
- Your `aleph.qgeom` Minkowski-sum error-box propagation is primarily **convex geometry / uncertainty propagation**, not tropical geometry per se.
- The “identity” is most accurate for the **piecewise-affine** interpretation, not for Minkowski sums.

Suggested rephrase (conceptually):
- “The network’s input-output map is a tropical-rational / spline object; the error-region tracking uses zonotope geometry that complements that view.”

### 2) “Integer weights” requirement in tropical rational equivalence
The doc says Zhang et al. prove ReLU networks with integer weights are exactly tropical rational maps.

This is plausible in spirit, but the precise conditions matter:
- Some results depend on representing operations in max-plus algebra; others are “tropicalization” limits.
- If integer weights are required for exact equivalence, say explicitly why (e.g. closure under the semiring, coefficient/exponent interpretation).

Without verifying the paper text right now, this should be softened to:
- “Under appropriate conditions (often stated for integer weights), ReLU networks can be represented as tropical rational maps.”

### 3) “Each dual subdivision cell corresponds to one activation pattern”
This is broadly right as a conceptual link, but for deep networks the mapping between activation patterns and the Newton polytope subdivision can be subtle (especially for rational functions / differences of convex PL functions).

This is OK in an expository doc, but it should be framed as:
- “Cells correspond to linear pieces / regions; in neural nets these are indexed by activation patterns.”

### 4) VQ/K-means language
“Spline partition = vector quantization; literally K-means-like clustering” is a useful intuition, but “literally” is too strong unless you give a precise equivalence (e.g. power diagram structure, explicit centroid assignment).

---

## What’s missing (to better serve your project goals)

### 1) A clean bridge from quantization mechanics to the tropical/spline formalism
Right now the doc jumps from “quantize weights” → “perturb tropical coefficients c_α”.

To make this defensible, you need one bridging section:
- what object in the tropical/spline representation is being perturbed by *rounding weights to a lattice*?
- how does activation quantization (grid snapping) appear in this representation?

Concretely, you likely want to separate:
- **weight quantization**: parameter perturbation of a PL map
- **activation quantization**: state-dependent projection onto a lattice (introduces discontinuities even without ReLU)
- **clipping/saturation**: projection onto a bounded polytope (hard collapse)

### 2) “Before collapse” vs “after collapse” as explicit geometry
Your project’s core is: *affine transport + additive noise* is correctable; collapse is not.

The doc should explicitly define:
- A “stable region” event: activation pattern unchanged + no saturation
- A “collapse event”: ReLU flips or saturation

and show how each maps to:
- within-cell affine perturbation
- boundary crossing / cell change

### 3) A definition of the manifold you’re tracking
The doc uses “manifold” heavily (circle, line, etc.), but doesn’t formalize what statistics are invariant under parameter perturbation:
- are we tracking Hausdorff distance between manifolds?
- are we tracking distortion of tangent directions (Jacobian action)?
- are we tracking change in region membership along the manifold?

Even a short “manifold diagnostics” subsection would make this actionable.

### 4) A “tooling map” aligned to your new overnight experiments
Given you’re now running Q1/Q2 experiments, it would help to add a small mapping:
- Q1: per-layer linear recoverability bound (best linear map) ↔ within-region affine theory
- Q2: generic corrector from quantization-time stats ↔ learning perturbation compensation conditioned on local features

---

## Actionable improvements (without changing the overall story)

1) Fix the zonotope vertex bound (or remove the exact formula and keep qualitative scaling in 2D/3D).
2) Replace the MASO Lipschitz formula with a norm-explicit “upper bound” statement.
3) Scope “exact zonotope” to the linear + Minkowski-sum regime.
4) Add one bridging section: “How rounding/clipping relate to tropical/spline parameters”.
5) Add a short “manifold metrics” section: distance/distortion/flip density along manifold.

---

## Suggested “tomorrow morning” checks this doc should motivate
(These align well with your current runner outputs.)

- Does `relu_flip_rate` concentrate where the manifold approaches pre-activation hyperplanes? (boundary proximity)
- Does linear recoverability drop mainly with higher flip/saturation, or also within stable regions (conditioning)?
- Do quantization-time features explain error beyond layer identity (Q2 supported)?
